{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Object Detection\n",
    "\n",
    "This attempt at object detection takes images of size 448x448 (scaling to this size if necessary),\n",
    "and walks through it with a window of size 224x224 (in total 7x7=49 positions).\n",
    "For each window it uses a pretrained image classifier from vgg16\n",
    "(https://neurohive.io/en/popular-networks/vgg16/).\n",
    "\n",
    "It then reports for top classes (manually selected) the top windows and shows them.\n",
    "\n",
    "The code is almost literally taken from https://github.com/DOsinga/deep_learning_cookbook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import vgg16\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Flatten, Dense, Input, TimeDistributed\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "from keras.preprocessing import image\n",
    "from PIL import ImageDraw\n",
    "\n",
    "from scipy.misc import imread, imresize, imsave, fromimage, toimage\n",
    "\n",
    "try:\n",
    "    from io import BytesIO\n",
    "except ImportError:\n",
    "    from StringIO import StringIO as BytesIO\n",
    "import PIL\n",
    "from IPython.display import clear_output, Image, display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Routines\n",
    "\n",
    "Some helper routines to pre-process an image, and to show a pre-processed image again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showarray(a, fmt='jpeg'):\n",
    "    f = BytesIO()\n",
    "    PIL.Image.fromarray(a).save(f, fmt)\n",
    "    display(Image(data=f.getvalue()))\n",
    "\n",
    "def preprocess_image(image_path, target_size=None):\n",
    "    img = load_img(image_path, target_size=target_size)\n",
    "    img = img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = vgg16.preprocess_input(img)\n",
    "    return img\n",
    "\n",
    "def deprocess_image(x, w, h):\n",
    "    x = x.copy()\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        x = x.reshape((3, w, h))\n",
    "        x = x.transpose((1, 2, 0))\n",
    "    else:\n",
    "        x = x.reshape((w, h, 3))\n",
    "    # Remove zero-center by mean pixel\n",
    "    x[:, :, 0] += 103.939\n",
    "    x[:, :, 1] += 116.779\n",
    "    x[:, :, 2] += 123.68\n",
    "    # 'BGR'->'RGB'\n",
    "    x = x[:, :, ::-1]\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading pretrained classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = vgg16.VGG16(weights='imagenet', include_top=True)\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading image\n",
    "\n",
    "Loading an image, preprocess it, and output the preprocessed image for verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_dog2 = preprocess_image('data/cat_dog.jpg', target_size=(448, 448))\n",
    "showarray(deprocess_image(cat_dog2, 448, 448))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating regions\n",
    "\n",
    "Using a sliding 224x224 window, create 49 regions which will then be classified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crops = []\n",
    "rects = []\n",
    "for x in range(7):\n",
    "    for y in range(7):\n",
    "        crops.append(cat_dog2[0, x * 32: x * 32 + 224, y * 32: y * 32 + 224, :])\n",
    "        rects.append((y * 32, x * 32, 224 + y * 32, 224 + x * 32))\n",
    "crops = np.asarray(crops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run classifier and show top results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = base_model.predict(vgg16.preprocess_input(crops))\n",
    "crop_scores = defaultdict(list)\n",
    "for idx, pred in enumerate(vgg16.decode_predictions(preds, top=1)):\n",
    "    _, label, weight = pred[0]\n",
    "    crop_scores[label].append((idx, weight))\n",
    "crop_scores.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show top results\n",
    "\n",
    "Using manually selected classes, show the top regions for the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_best_region_for_label(l, draw, label, color=(0,0,0)):\n",
    "    idx = max(l[label], key=lambda t:t[1])[0]\n",
    "    draw.rectangle(rects[idx], outline=color)\n",
    "    \n",
    "cat_dog_img = image.load_img('data/cat_dog.jpg', target_size=(448, 448))\n",
    "draw = ImageDraw.Draw(cat_dog_img)\n",
    "draw_best_region_for_label(crop_scores, draw, 'Egyptian_cat', (255,0,0))\n",
    "draw_best_region_for_label(crop_scores, draw, 'Labrador_retriever', (0,255,0))\n",
    "cat_dog_img"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
